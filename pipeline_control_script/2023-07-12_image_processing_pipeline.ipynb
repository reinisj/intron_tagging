{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c23a3b6f-ad87-4b7f-a928-46060aa6514a",
   "metadata": {},
   "source": [
    "# Image processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e34f3d-12d7-47ff-9ed4-9b112b2aa1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683035d7-4ae0-41e6-af6b-a00ca22b76e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracts Opera run (measurement) name from the full path\n",
    "get_run_name = lambda x: x.rstrip(\"/\").split(\"/\")[-1]\n",
    "# helper functions\n",
    "contains_pattern = lambda string,patterns: sum(np.array([[p in string] for p in patterns]).flatten())\n",
    "move_columns_to_front = lambda df, cols: df[cols + [column for column in df.columns if column not in cols]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acbc1b9-1c52-4a0c-b705-9181407c80bb",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69402d12-abc5-4394-ab8a-9497c6f9d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will be also the name of the main analysis folder with all processed files\n",
    "analysis_name = \"2023-06-16_HAP1_cancer_41_clones_large_pooled_screen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb7a6dc-dd1b-4600-8c24-fc17b2c5ca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to raw measurements exported from the Opera - after running flatfield correction script from Harmony computer\n",
    "# space before measurement number needs to be changed to underscore\n",
    "Opera_runs = [\n",
    "    \"/research/lab_kubicek/jreinis/Opera_images/2023-06-15_HAP1_cancer_41_clones_large_pooled_screen_repeat_suspicousplate/AR_20230614_HAP1_cancer_41clones_pooled_cpdplate_2313010_plate1__2023-06-14T18_00_48-Measurement_1\",\n",
    "    \"/research/lab_kubicek/jreinis/Opera_images/2023-06-15_HAP1_cancer_41_clones_large_pooled_screen_repeat_suspicousplate/AR_20230614_HAP1_cancer_41clones_pooled_cpdplate_2313010_plate1__2023-06-15T03_26_51-Measurement_2\",\n",
    "    \"/research/lab_kubicek/jreinis/Opera_images/2023-06-15_HAP1_cancer_41_clones_large_pooled_screen_repeat_suspicousplate/AR_20230614_HAP1_cancer_41clones_pooled_cpdplate_2313010_plate2__2023-06-14T21_28_13-Measurement_1\",\n",
    "    \"/research/lab_kubicek/jreinis/Opera_images/2023-06-15_HAP1_cancer_41_clones_large_pooled_screen_repeat_suspicousplate/AR_20230614_HAP1_cancer_41clones_pooled_cpdplate_2313010_plate2__2023-06-15T06_54_56-Measurement_2\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0fac8c-da1c-4556-9fd7-4198900997c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required for hit calling\n",
    "platemap_path = \"/research/lab_kubicek/jreinis/Opera_images/2023-06-15_HAP1_cancer_41_clones_large_pooled_screen_repeat_suspicousplate/JR_20230616_Pool41_Experiments_Compounds_Plates_parsed_v4_all_new_measurements.csv\"\n",
    "clones_metadata_path = \"/research/lab_kubicek/jreinis/Opera_images/2023-06-15_HAP1_cancer_41_clones_large_pooled_screen_repeat_suspicousplate/pool_of_41_cleaned_metadata_newOpera.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c9188b-21eb-4f67-8279-d42d287ab93d",
   "metadata": {},
   "source": [
    "## Pipeline config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce99c37f-e970-4f61-8dcb-2fe415ae6ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_files_folder_root = \"/nobackup/lab_kubicek/jreinis/Opera_images_processed\"\n",
    "tmp_folder_root = \"/nobackup/lab_kubicek/jreinis/batch_processing_temp_files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bea83fc-a9c7-4971-953a-928a8887c37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel name, desired number, number in dataset\n",
    "channels_order = [\n",
    "    (\"GFP\", 1, 3),\n",
    "    (\"mScarlet\", 2, 5),\n",
    "    (\"BFP\", 3, 1),\n",
    "    (\"mAmetrine\", 4, 2),\n",
    "    (\"miRFP\", 5, 4),\n",
    "]\n",
    "\n",
    "# suffixes of 1:1 mapping output masks\n",
    "mapped_1_1_suffixes = {\n",
    "    \"filtered_cells\": \"_filtered_cells.png\",\n",
    "    \"filtered_cytoplasm\": \"_filtered_cytoplasm.png\",\n",
    "    \"filtered_nuclei\": \"_filtered_nuclei.png\",\n",
    "}\n",
    "\n",
    "# default cluster queue\n",
    "cluster_queue = \"shortq\"\n",
    "\n",
    "# FFC-correction and separation settings\n",
    "zip_preFFC = True    # create a backup of the files before FFC correction\n",
    "zip_postFFC = True   # create a backup of the FFC-corrected files\n",
    "delete_flex = True   # delete the original folder with FFC_corrected images after copying them\n",
    "rename_utility_path = \"/cm/shared/specific/apps/util-linux/2.36-GCCcore-10.2.0/bin/rename\" # path to rename script from linux-utils: `rename old_pattern new_pattern files`\n",
    "separate_FFC_script_body = \"/home/jreinis/pipeline_scripts/separate_FFC_zip_partial.sh\"\n",
    "\n",
    "# slurm-specific settings\n",
    "maximum_memory = \"35000\"\n",
    "max_arr_jobs = 1000\n",
    "\n",
    "# parameters for JPEG conversion\n",
    "cluster_queue_JPEG = \"shortq\"\n",
    "run_JPEG_conversion_script = \"/home/jreinis/pipeline_scripts/run_JPEG_conversion.py\"\n",
    "extract_separate_chans = False\n",
    "JPEG_quality=\"92\" \n",
    "JPEG_resize_res=\"1080\"\n",
    "background_intensities = [0, 0, 0, 0, 0] # background intensity value for each channel - is subtracted for the visualization purposes\n",
    "minq = 0.05                              # minimum quantile parameter for quantile normalization of the images\n",
    "maxq = 0.9975                            # maximum quantile parameter for quantile normalization of the images\n",
    "gamma = 1.00                             # gamma parameter for the visualization\n",
    "\n",
    "# segmentatation and 1:1 mapping parameters\n",
    "segmentation_batch_size = 20\n",
    "cluster_queue_segmentation = \"tinyq\"\n",
    "cellpose_script = \"/home/jreinis/pipeline_scripts/run_cellpose_batch.py\"\n",
    "nucleaizer_script = \"/home/jreinis/pipeline_scripts/run_nucleAIzer_batch_bleedthrough_correction.py\"\n",
    "mapping_script = \"/home/jreinis/pipeline_scripts/run_1_1_mapping.py\"\n",
    "nucleaizer_model_path = \"/home/jreinis/saved_models/mask_rcnn_general.h5\"\n",
    "colormap_path = \"/home/jreinis/cellprofiler_pipelines/2022-03-18-glasbey_light.npy\"\n",
    "generate_inspection_imgs = False\n",
    "nuclei_min_size = 750             # discard nuclei below area in px\n",
    "cells_min_size = 1500             # discard cells below area in px\n",
    "nuclei_overlap_min = 0.66         # minimal proportion of the area of a nucleus to lie within a cell to be assigned to it\n",
    "NC_threshold_lower = 0.2          # discard cells below nuclear:cytoplasmic area threshold\n",
    "NC_threshold_upper = 0.65         # discard cells above nuclear:cytoplasmic area threshold\n",
    "FOV_border_px = 2                 # width of band around the FOV border, nuclei/cells within this area will be discarded\n",
    "expand_px = 5                     # how many pixels to expand the mask of a cell when looking for neighboring ones\n",
    "noborder_strict_mode = \"chilled\"  # strict mode (\"strict\") = discard CELLS touching border, non-strict mode = discard cells with NUCLEI touching border\n",
    "apopt_thres_nuclei = 2000         # apply stricter filtering criteria to cells with nuclei below this size\n",
    "apopt_thres_cells = 5000          # apply stricter filtering criteria to cells below this size\n",
    "solidity_threshold = 0.95         # discard (apoptotic) cells with solidity above threshold\n",
    "eccentricity_threshold = 1.4      # discard (apoptotic) cells with sum of cell+nucleus eccentricity above threshold\n",
    "\n",
    "# segmented cell counting\n",
    "cluster_queue_counting = \"tinyq\"\n",
    "cell_counting_script = \"/home/jreinis/pipeline_scripts/count_segmented_cells.py\"\n",
    "    \n",
    "# cellprofiler parameters\n",
    "cluster_queue_cellprofiler = \"tinyq\"\n",
    "cellprofiler_batch_size = 30\n",
    "cellprofiler_pipeline = \"/home/jreinis/cellprofiler_pipelines/2022-02-18_CLUSTER_5channel_v7_no_1_1_mapping.cppipe\"\n",
    "cellprofiler_batch_merging_script = \"/home/jreinis/pipeline_scripts/merge_cellprofiler_batches.py\"\n",
    "index_xml_filename = \"index.xml\"  # contains positions of FOVs, different Harmony software versions have different names\n",
    "opera_harmony_version = \"V6\"      # different Harmony software versions have a slightly different structure of the index XML file\n",
    "\n",
    "# saving cellprofiler/random forest predictions\n",
    "cluster_queue_get_predictions = \"tinyq\"\n",
    "get_rf_predictions_script = \"/home/jreinis/pipeline_scripts/get_predictions_cellprofiler_rf.py\"\n",
    "rf_model_path = \"/home/jreinis/saved_models/2023-03-28_HAP1_cancer_41_clones_newOpera_nomix_additional_E07all.joblib\"\n",
    "\n",
    "# visualizing cellprofiler/random forest predictions\n",
    "cluster_queue_visualize_predictions = \"shortq\"\n",
    "visualize_predictions_script = \"/home/jreinis/pipeline_scripts/get_visualizations_predictions.py\"\n",
    "color_code_probabilities = 1\n",
    "\n",
    "# post-perturbation detection parameters\n",
    "cluster_queue_post_perturb_detection = \"shortq\"\n",
    "extract_spatial_info_script = \"/home/jreinis/pipeline_scripts/get_spatial_info.py\"\n",
    "combine_predictions_script = \"/home/jreinis/pipeline_scripts/combine_predictions_spatial.py\"\n",
    "radius = 350      # radius in pixels to use to when fetching the neighboring cells\n",
    "rf_models_channels_subsets = {\n",
    "    \"all_but_GFP\": \"/home/jreinis/saved_models/2023-03-28_HAP1_cancer_41_clones_newOpera_nomix_additional_E07all_but_GFP.joblib\",\n",
    "    \"all_but_mScarlet\": \"/home/jreinis/saved_models/2023-03-28_HAP1_cancer_41_clones_newOpera_nomix_additional_E07all_but_mScarlet.joblib\",\n",
    "    \"BFP_only\": \"/home/jreinis/saved_models/2023-03-28_HAP1_cancer_41_clones_newOpera_nomix_additional_E07BFP_only.joblib\",\n",
    "    \"BFP_structural\": \"/home/jreinis/saved_models/2023-03-28_HAP1_cancer_41_clones_newOpera_nomix_additional_E07BFP_structural.joblib\",\n",
    "}\n",
    "\n",
    "# hit calling parameters\n",
    "cluster_queue_hit_calling = \"tinyq\"\n",
    "features_to_test_path = \"/home/jreinis/cellprofiler_pipelines/2023-04-13_hit_calling_features_use_test.csv\"\n",
    "test_statistic_cellprofiler_script = \"/home/jreinis/pipeline_scripts/tests_statistics_cellprofiler_features.py\"\n",
    "\n",
    "# visualizing timecourses\n",
    "visualize_timecourses_script_path = \"/home/jreinis/pipeline_scripts/visualize_predictions_timecourse.py\"\n",
    "size_tile_overlay = 10\n",
    "show_labels = 1\n",
    "color_code_probas = 1\n",
    "generate_separate_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb92fcd2-c101-47bc-89d0-73751b9251f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### prepare renumbering of different channels\n",
    "channels_order = pd.DataFrame(channels_order, columns = [\"name\", \"analysis_index\", \"dataset_index\"])\n",
    "chan_suffixes = {name:f\"-ch{ch}sk1fk1fl1.tiff\" for name,ch in zip(channels_order[\"name\"],channels_order[\"analysis_index\"])}\n",
    "channels_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed5cc8-43ff-414a-aab2-6639c61b0d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save processed run folders in a variable\n",
    "processed_runs = [f\"{processed_files_folder_root}/{analysis_name}/{get_run_name(run)}_FFC\" for run in Opera_runs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b348dad-625a-4902-b4ef-daffa1698e88",
   "metadata": {},
   "source": [
    "## Prepare folders and variables\n",
    "1. create folder named `analysis_name` in `processed_files_folder`\n",
    "2. for each processed measurement create a folder named `[measurement name from Opera] + \"_FFC\"`\n",
    "3. store all processed files + scripts + logs there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb96091-6195-4f6f-bd6e-1c1b14d6dbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_files_folder = f\"{processed_files_folder_root}/{analysis_name}\"\n",
    "tmp_files_folder = f\"{tmp_folder_root}/{analysis_name}\"\n",
    "scripts_folder = f\"{processed_files_folder}/scripts\"\n",
    "logs_folder = f\"{processed_files_folder}/logs\"\n",
    "hit_calling_folder = f\"{processed_files_folder}/hit_calling\"\n",
    "analysis_metadata_folder = f\"{processed_files_folder}/metadata\"\n",
    "\n",
    "os.system(f\"mkdir -p {processed_files_folder} {tmp_files_folder} {scripts_folder} {logs_folder}\")\n",
    "print(f\"creating root folders for analysis: {analysis_name}\\n {processed_files_folder}\\n {scripts_folder}\\n {tmp_files_folder}\\n\")\n",
    "print(f\"creating subfolders for measurements\") \n",
    "\n",
    "for run_folder_FFC in processed_runs:\n",
    "    # extract the name of the Opera run from the filepath\n",
    "    run_name = get_run_name(run_folder_FFC)\n",
    "\n",
    "    # output files go here\n",
    "    metadata_folder = f\"{run_folder_FFC}/Images_metadata/\"\n",
    "    output_folder_tagged_JPEG = f\"{run_folder_FFC}/Images_tagged_chans_JPEG/\"\n",
    "    output_folder_structural_JPEG = f\"{run_folder_FFC}/Images_structural_chans_JPEG/\"\n",
    "    output_folder_channels_JPEG = f\"{run_folder_FFC}/Images_separate_chans_JPEG/\"\n",
    "    output_folder_segmented = f\"{run_folder_FFC}/Images_segmented/\"\n",
    "    output_folder_segmented_inspect = f\"{run_folder_FFC}/Images_segmented_inspect/\"\n",
    "    output_folder_cellprofiler = f\"{run_folder_FFC}/CellProfiler_measurements/\"\n",
    "    output_folder_extracted_cells = f\"{run_folder_FFC}/Images_extracted_cells/\"\n",
    "    output_folder_cytoself = f\"{run_folder_FFC}/Cytoself_measurements/\"\n",
    "    output_folder_cellprofiler_predictions = f\"{run_folder_FFC}/Predictions_CellProfiler_RF/\"\n",
    "    \n",
    "    # generated bash scripts go here   \n",
    "    scripts_folder_separateFFC = f\"{scripts_folder}/{run_name}/00_FFC_separate/\"\n",
    "    scripts_folder_JPEG = f\"{scripts_folder}/{run_name}/01_JPEG_convert/\"\n",
    "    scripts_folder_segmentation = f\"{scripts_folder}/{run_name}/02_segmentation/\"\n",
    "    scripts_folder_counting = f\"{scripts_folder}/{run_name}/03_count_segmented_cells/\"\n",
    "    scripts_folder_cellprofiler = f\"{scripts_folder}/{run_name}/04_cellprofiler/\"\n",
    "    scripts_folder_get_cp_predictions = f\"{scripts_folder}/{run_name}/05_cellprofiler_predictions/\"\n",
    "    scripts_folder_visualize_cp_predictions = f\"{scripts_folder}/{run_name}/06_visualize_cellprofiler_predictions/\"\n",
    "    scripts_folder_extraction = f\"{scripts_folder}/{run_name}/06_cell_extraction/\"\n",
    "    scripts_folder_cytoself = f\"{scripts_folder}/{run_name}/07_cytoself/\"\n",
    "\n",
    "    tmp_folder_run = f\"{tmp_files_folder}/{run_name}\"\n",
    "    # temp folder for intermediary files, e.g. cellprofiler measurements batches that need to be merged\n",
    "    tmp_folder_cellprofiler = f\"{tmp_folder_run}/cellprofiler_temp/\"\n",
    "    \n",
    "    # run the folder creation commands\n",
    "    os.system(f\"mkdir -p {metadata_folder} {output_folder_tagged_JPEG} {output_folder_structural_JPEG} {output_folder_channels_JPEG}\")\n",
    "    os.system(f\"mkdir -p {output_folder_segmented} {output_folder_segmented_inspect} {output_folder_cellprofiler} {output_folder_cellprofiler_predictions}\")\n",
    "#    os.system(f\"mkdir -p {output_folder_extracted_cells} {output_folder_cytoself}\")\n",
    "   \n",
    "    os.system(f\"mkdir -p {scripts_folder_separateFFC} {scripts_folder_JPEG} {scripts_folder_segmentation} {scripts_folder_counting}\")\n",
    "    os.system(f\"mkdir -p {scripts_folder_cellprofiler}\")\n",
    "    os.system(f\"mkdir -p {scripts_folder_get_cp_predictions} {scripts_folder_visualize_cp_predictions}\")\n",
    "#    os.system(f\"mkdir -p {scripts_folder_extraction} {scripts_folder_cytoself}\")\n",
    "    \n",
    "    os.system(f\"mkdir -p {tmp_folder_cellprofiler}\")\n",
    "\n",
    "    print(f\" {run_name}\")\n",
    "print()\n",
    "    \n",
    "#### if hit calling: copy platemap and clones metadata to the analysis folder\n",
    "# folder to save statistical tests results\n",
    "if \"platemap_path\" in locals() and \"clones_metadata_path\" in locals():\n",
    "    os.system(f\"mkdir -p {hit_calling_folder}\")\n",
    "    os.system(f\"mkdir -p {analysis_metadata_folder}\")\n",
    "    print(\"creating folders for hit calling\", \" \"+analysis_metadata_folder, \" \"+hit_calling_folder, sep=\"\\n\", end=\"\\n\")\n",
    "    \n",
    "# copy platemap and clones_metadata to the analysis folder\n",
    "if \"platemap_path\" in locals():\n",
    "    platemap_path_cp = f'{analysis_metadata_folder}/{platemap_path.split(\"/\")[-1]}'\n",
    "    os.system(f'cp {platemap_path} {platemap_path_cp}')\n",
    "    print(f\"copying platemap to {processed_files_folder_root}/{analysis_name}\")\n",
    "if \"clones_metadata_path\" in locals():\n",
    "    clones_metadata_path_cp = f'{analysis_metadata_folder}/{clones_metadata_path.split(\"/\")[-1]}'\n",
    "    os.system(f'cp {clones_metadata_path} {clones_metadata_path_cp}')\n",
    "    print(f\"copying clones metadata to {processed_files_folder_root}/{analysis_name}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff3e539-61a9-48b1-a378-6c31a84b2ab7",
   "metadata": {},
   "source": [
    "## 0. Separate FFC-corrected images, zip original for backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2801ee-24f6-4f3c-aacd-e6af17c0cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_script_path = f'{scripts_folder}/{analysis_name}_00_separate_FFC_zip.sh'\n",
    "with open(master_script_path, mode='w', encoding='utf-8') as f:\n",
    "            f.write(\"#!/bin/bash\\n\\n\")\n",
    "\n",
    "for run_folder, run_folder_FFC in zip(Opera_runs, processed_runs):\n",
    "    run_name = get_run_name(run_folder_FFC)\n",
    "    scripts_folder_separateFFC = f\"{scripts_folder}/{run_name}/00_FFC_separate\"\n",
    "    script_path = f\"{scripts_folder_separateFFC}/{run_name}_00_separate_FFC_zip.sh\"\n",
    "    \n",
    "    zip_preFFC_param = f'{run_folder}_pre_FFC.zip' if zip_preFFC else \"False\"\n",
    "    zip_postFFC_param = f'{run_folder}_post_FFC.zip' if zip_postFFC else \"False\"\n",
    "    \n",
    "    script_head = \"\\n\".join([f\"#!/bin/bash\",\n",
    "                             f\"#SBATCH --output {logs_folder}/job_%j_{run_name}_separate_FFC_zip.log\",\n",
    "                             f\"#SBATCH --error {logs_folder}/job_%j_{run_name}_separate_FFC_zip.log\",\n",
    "                             f\"#SBATCH --job-name=FFC_sep\",\n",
    "                             f\"#SBATCH --partition={cluster_queue}\",\n",
    "                             f\"#SBATCH --qos={cluster_queue}\\n\",\n",
    "                             f\"source /home/${{USER}}/.bashrc\\n\",\n",
    "                             \"date; echo\\n\\n\"])\n",
    "\n",
    "    script_config = \"\\n\".join([\n",
    "        f'measurement=\"{run_folder}\"',\n",
    "        f'measurement_FFC=\"{run_folder_FFC}\"',\n",
    "        f'zip=\"{zip_preFFC_param}\"',\n",
    "        f'zip_FFC=\"{zip_postFFC_param}\"',\n",
    "        f'delete_flex=\"{delete_flex}\"',\n",
    "        f'rename_script=\"{rename_utility_path}\"',\n",
    "        f'channels_order=({\" \".join(channels_order[\"dataset_index\"].astype(str))})\\n\\n',\n",
    "    ])\n",
    "    \n",
    "    # load the part of the script that is always the same\n",
    "    with open(separate_FFC_script_body, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "        script_body = f.read()\n",
    "    \n",
    "    with open(script_path, mode='w', encoding='utf-8') as f:\n",
    "        f.write(script_head)\n",
    "        f.write(script_config)\n",
    "        f.write(script_body)\n",
    "    \n",
    "    with open(master_script_path, mode='a', encoding='utf-8') as f:\n",
    "        f.write(f\"chmod ug+rx {script_path}\\n\")\n",
    "        f.write(f\"sbatch {script_path}\\n\\n\")\n",
    "\n",
    "print(f\"chmod ug+rx {master_script_path}\")\n",
    "print(f\"{master_script_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20919054-f429-4ffb-a3f4-529596c1825a",
   "metadata": {},
   "source": [
    "## Prepare imagelist metadata file\n",
    "- metadata file with paths and filenames to raw and processed files for each FOV\n",
    "- required for CellProfiler - dictates also the structure\n",
    "- but used also by Cellpose scripts and cell extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dd2cc6-050f-4185-9d5b-d9f5f2ca117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_folder_FFC in tqdm(processed_runs):\n",
    "    run_name = get_run_name(run_folder_FFC)\n",
    "    \n",
    "    # csv path\n",
    "    metadata_folder = f\"{run_folder_FFC}/Images_metadata/\"\n",
    "    imagelist_csv_path = f\"{metadata_folder}/{run_name}_images_list.csv\"\n",
    "    \n",
    "    # folders\n",
    "    raw_tif_folder = f\"{run_folder_FFC}/Images_FFC/\"\n",
    "    output_folder_tagged_JPEG = f\"{run_folder_FFC}/Images_tagged_chans_JPEG/\"\n",
    "    output_folder_structural_JPEG = f\"{run_folder_FFC}/Images_structural_chans_JPEG/\"\n",
    "    output_folder_segmented = f\"{run_folder_FFC}/Images_segmented/\"\n",
    "    output_folder_extracted_cells = f\"{run_folder_FFC}/Images_extracted_cells/\"\n",
    "\n",
    "    # load list of images (FOVs)\n",
    "    FOVs = list(sorted(set([x.split(\"-\")[0] for x in os.listdir(raw_tif_folder) if x.endswith(\".tiff\")])))\n",
    "\n",
    "    # variable to store all the metadata in a dictionary\n",
    "    imagelist = {}\n",
    "      \n",
    "    # prepare the fields in the csv file\n",
    "    # FOV IDs (e.g. r01c01f04p01)\n",
    "    imagelist[\"FOV\"] = FOVs\n",
    "    \n",
    "    # required for CellProfiler?\n",
    "    imagelist[\"Group_Number\"] = 1\n",
    "    \n",
    "    # raw image files - 5 files per FOV, for each path + filename + URL (=\"file:/\"+path+filename)\n",
    "    for chan, suffix in chan_suffixes.items():\n",
    "        imagelist[\"FileName_\"+chan] = [img+suffix for img in FOVs]\n",
    "        imagelist[\"PathName_\"+chan] = raw_tif_folder\n",
    "        imagelist[\"URL_\"+chan] = [\"file:\"+raw_tif_folder+filename for filename in imagelist[\"FileName_\"+chan]]\n",
    "\n",
    "    # tagged/structural channels\n",
    "    imagelist[\"FileName_tagged_chans\"] = [img + \"_tagged_channels.jpg\" for img in FOVs]\n",
    "    imagelist[\"PathName_tagged_chans\"] = output_folder_tagged_JPEG\n",
    "    imagelist[\"URL_tagged_chans\"] = [\"file:\"+output_folder_tagged_JPEG+filename for filename in imagelist[\"FileName_tagged_chans\"]]\n",
    "    imagelist[\"FileName_structural_chans\"] = [img + \"_structural_channels.jpg\" for img in FOVs]\n",
    "    imagelist[\"PathName_structural_chans\"] = output_folder_structural_JPEG\n",
    "    imagelist[\"URL_structural_chans\"] = [\"file:\"+output_folder_structural_JPEG+filename for filename in imagelist[\"FileName_structural_chans\"]]\n",
    "    \n",
    "    # segmented output names\n",
    "    imagelist[\"FileName_segmented_cells_mask\"] = [img + chan_suffixes[\"mAmetrine\"][:-5] + \"_segmented_mask.png\" for img in FOVs]\n",
    "    imagelist[\"PathName_segmented_cells_mask\"] = output_folder_segmented\n",
    "    imagelist[\"URL_segmented_cells_mask\"] = [\"file:\"+output_folder_segmented+filename for filename in imagelist[\"FileName_segmented_cells_mask\"]]\n",
    "    imagelist[\"FileName_segmented_nuclei_mask\"] = [img + chan_suffixes[\"miRFP\"][:-5] + \"_segmented_mask.png\" for img in FOVs]\n",
    "    imagelist[\"PathName_segmented_nuclei_mask\"] = output_folder_segmented\n",
    "    imagelist[\"URL_segmented_nuclei_mask\"] = [\"file:\"+output_folder_segmented+filename for filename in imagelist[\"FileName_segmented_nuclei_mask\"]]\n",
    "\n",
    "    # 1:1 mapping output: cells, nuclei, cytoplasm\n",
    "    for component, suffix in mapped_1_1_suffixes.items():\n",
    "        imagelist[\"FileName_\"+component] = [img+suffix for img in FOVs]\n",
    "        imagelist[\"PathName_\"+component] = output_folder_segmented\n",
    "        imagelist[\"URL_\"+component] = [\"file:\"+output_folder_segmented+filename for filename in imagelist[\"FileName_\"+component]]\n",
    "        \n",
    "    # extracted masks\n",
    "    imagelist[\"PathName_extracted_cells\"] = output_folder_extracted_cells\n",
    "    imagelist[\"FileName_extracted_cells\"] = [img + \"_extracted_cells.h5\" for img in FOVs]\n",
    "    imagelist[\"URL_extracted_cells\"] = [\"file:\"+output_folder_extracted_cells+filename for filename in imagelist[\"FileName_extracted_cells\"]]\n",
    "          \n",
    "    # cytoself\n",
    "    imagelist[\"PathName_cytoself\"] = output_folder_cytoself\n",
    "    imagelist[\"FileName_cytoself\"] = [img + \"_cytoself_features.h5\" for img in FOVs]\n",
    "    imagelist[\"URL_cytoself\"] = [\"file:\"+output_folder_cytoself+filename for filename in imagelist[\"FileName_cytoself\"]]\n",
    "\n",
    "    imagelist = pd.DataFrame(imagelist)\n",
    "    # Number the FOVs (required for batch processing)\n",
    "    imagelist = imagelist.reset_index()\n",
    "    imagelist.rename(columns={\"index\": \"Group_Index\"}, inplace=True)\n",
    "    # 1-based indexing for CellProfiler\n",
    "    imagelist[\"Group_Index\"] = imagelist[\"Group_Index\"] + 1\n",
    "    \n",
    "    # columns need to be in specific order (?) for CellProfiler, otherwise it does not seem to work\n",
    "    new_col_order = [\"Group_Number\", \"Group_Index\"]\n",
    "    # add file/path names\n",
    "    columns_URLs = [col for col in imagelist.columns if col.startswith(\"URL_\")]\n",
    "    columns_filenames = [col for col in imagelist.columns if col.startswith(\"FileName_\")]\n",
    "    columns_pathnames = [col for col in imagelist.columns if col.startswith(\"PathName_\")]\n",
    "    for cols in zip(columns_URLs, columns_filenames, columns_pathnames):\n",
    "            new_col_order.extend([cols[0], cols[1], cols[2]])\n",
    "    # FOV name\n",
    "    new_col_order += [\"FOV\"]\n",
    "    \n",
    "    # save reordered\n",
    "    imagelist[new_col_order].to_csv(imagelist_csv_path, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae27a203-6a7b-4eee-9af1-3a4974116576",
   "metadata": {},
   "source": [
    "## 1. JPEG conversion scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f95d85-885c-4cc2-b20f-f69c7c96ce9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JPEG conversion - add flag if \n",
    "sep_chans_par = {False:\"\", True:\"--separate \"}[extract_separate_chans]\n",
    "\n",
    "master_script_path = f'{scripts_folder}/{analysis_name}_01_run_JPEG_conversion.sh'\n",
    "with open(master_script_path, mode='w', encoding='utf-8') as f:\n",
    "        f.write(\"#!/bin/bash\\n\\n\")\n",
    "\n",
    "for run_folder_FFC in processed_runs:\n",
    "    run_name = get_run_name(run_folder_FFC)\n",
    "    scripts_folder_JPEG = f\"{scripts_folder}/{run_name}/01_JPEG_convert\"\n",
    "    script_path = f\"{scripts_folder_JPEG}/{run_name}_JPEG_convert.sh\"\n",
    "\n",
    "    script_head = \"\\n\".join([f\"#!/bin/bash\",\n",
    "                             f\"#SBATCH --output {logs_folder}/job_%j_{run_name}_JPEG_convert.log\",\n",
    "                             f\"#SBATCH --error {logs_folder}/job_%j_{run_name}_JPEG_convert.log\",\n",
    "                             \"#SBATCH --job-name=convert\",\n",
    "                             f\"#SBATCH --partition={cluster_queue_JPEG}\",\n",
    "                             f\"#SBATCH --qos={cluster_queue_JPEG}\\n\",\n",
    "                             f\"source /home/${{USER}}/.bashrc\\n\",\n",
    "                             \"date; echo\\n\\n\"])\n",
    "\n",
    "    script_body = \"\\n\".join([f\"measurement=\\\"{run_folder_FFC}/\\\"\",\n",
    "                             f\"quality={JPEG_quality}\",\n",
    "                             f\"resolution={JPEG_resize_res}\\n\",\n",
    "                             f\"gamma={gamma}\\n\",\n",
    "                             f'{run_JPEG_conversion_script} -m $measurement -r $resolution -q $quality {sep_chans_par} -g $gamma -b {\" \".join([str(x) for x in background_intensities])}\\n',\n",
    "                             \"echo; date\",\n",
    "                             \"sstat -j $SLURM_JOB_ID.batch --format=JobID,Node,MaxVMSize\\n\"])\n",
    "    \n",
    "    with open(script_path, mode='w', encoding='utf-8') as f:\n",
    "        f.write(script_head)\n",
    "        f.write(script_body)\n",
    "    \n",
    "    with open(master_script_path, mode='a', encoding='utf-8') as f:\n",
    "        f.write(f\"chmod ug+rx {script_path}\\n\")\n",
    "        f.write(f\"sbatch {script_path}\\n\\n\")\n",
    "\n",
    "print(f\"chmod ug+rx {master_script_path}\")\n",
    "print(f\"{master_script_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67d0d42-3fe7-472e-9c1f-72d8f88ea459",
   "metadata": {},
   "source": [
    "## 2. Segmentation scripts\n",
    "1. **cellpose** (cells)\n",
    "2. **nucleAIzer** (nuclei)\n",
    "3. **custom scripts** (1:1 mapping + filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b6eb3e-78e3-4492-8b36-a3c1d8158930",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_script_path = f'{scripts_folder}/{analysis_name}_02_run_segmentation.sh'\n",
    "with open(master_script_path, mode='w', encoding='utf-8') as f:\n",
    "        f.write(\"#!/bin/bash\\n\\n\")\n",
    "\n",
    "for run_folder_FFC in processed_runs:\n",
    "    run_name = get_run_name(run_folder_FFC)\n",
    "    # paths\n",
    "    scripts_folder_segmentation = f\"{scripts_folder}/{run_name}/02_segmentation/\"\n",
    "    metadata_folder = f\"{run_folder_FFC}/Images_metadata/\"\n",
    "    imagelist_csv_path = f\"{metadata_folder}/{run_name}_images_list.csv\"\n",
    "    output_folder_segmented_inspect = f\"{run_folder_FFC}/Images_segmented_inspect/\"\n",
    "\n",
    "    # load imagelist\n",
    "    imagelist = pd.read_csv(imagelist_csv_path)\n",
    "\n",
    "    n_batches = np.ceil(len(imagelist)/segmentation_batch_size).astype(\"int\")\n",
    "    \n",
    "    # prepare a script to run the segmentation in batches (using arrayed slurm jobs)\n",
    "    script_path = f\"{scripts_folder_segmentation}/{run_name}_02_run_segmentation.sh\"\n",
    "\n",
    "    # create the script - the array line ensures one script is run for each batch\n",
    "    script_head = \"\\n\".join([f\"#!/bin/bash\",\n",
    "                             f\"#SBATCH --output {logs_folder}/job_%A_%3a_{run_name}_segmentation.log\",\n",
    "                             f\"#SBATCH --error {logs_folder}/job_%A_%3a_{run_name}_segmentation.log\",\n",
    "                             f\"#SBATCH --mem={maximum_memory}\",\n",
    "                             f\"#SBATCH --job-name=segment\",\n",
    "                             f\"#SBATCH --partition={cluster_queue_segmentation}\",\n",
    "                             f\"#SBATCH --qos={cluster_queue_segmentation}\",\n",
    "                             f\"#SBATCH --array=0-{max(range(n_batches))}:1%{max_arr_jobs}\\n\", \n",
    "                             \"source /home/${USER}/.bashrc\\n\",\n",
    "                             \"date; echo\\n\",\n",
    "                             f\"echo {run_name}\\n\",\n",
    "                             'batch_i=$SLURM_ARRAY_TASK_ID',\n",
    "                             f'batch_size={segmentation_batch_size}\\n',\n",
    "                             'start=$(( batch_i*batch_size ))',\n",
    "                             'stop=$(( (batch_i+1)*batch_size ))\\n\\n'])#echo $batch_i $start $stop\\n'])\n",
    "    \n",
    "    # config\n",
    "    script_body = \"\\n\".join([f'imagelist={imagelist_csv_path}\\n\\n'])\n",
    "    \n",
    "    # cellpose part (cells)\n",
    "    script_body += \"\\n\".join([f\"conda activate cellpose\",\n",
    "                             f\"{cellpose_script} -i $imagelist -f $start -l $stop\\n\\n\"])\n",
    "    \n",
    "    # nucleaizer part (nuclei)\n",
    "    script_body += \"\\n\".join([f\"conda activate nucleaizer\",\n",
    "                             f'{nucleaizer_script} -i $imagelist -m {nucleaizer_model_path} -f $start -l $stop -n {minq} -x {maxq} -b {\" \".join([str(x) for x in background_intensities])}\\n',\n",
    "                             \"echo; date\\n\"]) \n",
    "    \n",
    "    # 1:1 mapping part\n",
    "    mapping_script_command = f'{mapping_script} -i $imagelist -f $start -l $stop -Nm {nuclei_min_size} -Cm {cells_min_size} -o {nuclei_overlap_min} -L {NC_threshold_lower} -U {NC_threshold_upper} -b {FOV_border_px} '\n",
    "    if generate_inspection_imgs:\n",
    "            mapping_script_command += f'-O {output_folder_segmented_inspect} '\n",
    "    mapping_script_command += f'-s {noborder_strict_mode} -e {expand_px} -c {colormap_path} -Na {apopt_thres_nuclei} -Ca {apopt_thres_cells} -S {solidity_threshold} -E {eccentricity_threshold}'\n",
    "    script_body += \"\\n\".join([f\"conda activate base\",\n",
    "                             mapping_script_command,\n",
    "                             \"echo; date\",\n",
    "                             \"sstat -j $SLURM_JOB_ID.batch --format=JobID,Node,MaxVMSize\\n\"])\n",
    "    #print(script_path)\n",
    "    # save\n",
    "    with open(script_path, mode='w', encoding='utf-8') as f:\n",
    "        f.write(script_head)\n",
    "        f.write(script_body)\n",
    "            \n",
    "    with open(master_script_path, mode='a', encoding='utf-8') as f:\n",
    "        f.write(f\"chmod ug+rx {script_path}\\n\")\n",
    "        f.write(f\"sbatch {script_path}\\n\\n\")\n",
    "\n",
    "print(f\"chmod ug+rx {master_script_path}\")\n",
    "print(f\"{master_script_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bc838c-ba4a-491f-8ffc-85becf1a2779",
   "metadata": {},
   "source": [
    "## 3. Count segmented cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b61bd39-5eba-4b5b-9e70-1cefbdb39fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_script_path = f'{scripts_folder}/{analysis_name}_03_count_segmented_cells.sh'\n",
    "with open(master_script_path, mode='w', encoding='utf-8') as f:\n",
    "        f.write(\"#!/bin/bash\\n\\n\")\n",
    "\n",
    "for run_folder_FFC in processed_runs:\n",
    "    run_name = get_run_name(run_folder_FFC)\n",
    "    scripts_folder_counting = f\"{scripts_folder}/{run_name}/03_count_segmented_cells/\"\n",
    "    script_path = f\"{scripts_folder_counting}{run_name}_03_count_segmented_cells.sh\"\n",
    "    \n",
    "    # define folders/parameters to pass on to script\n",
    "    metadata_folder = f\"{run_folder_FFC}/Images_metadata/\"\n",
    "    imagelist_csv_path = f\"{metadata_folder}/{run_name}_images_list.csv\"\n",
    "    cell_counts_csv_path = f\"{metadata_folder}/{run_name}_cell_counts.csv\"\n",
    "       \n",
    "    script_head = \"\\n\".join([f\"#!/bin/bash\",\n",
    "                             f\"#SBATCH --output {logs_folder}/job_%j_{run_name}_count_segmented_cells.log\",\n",
    "                             f\"#SBATCH --error {logs_folder}/job_%j_{run_name}_count_segmented_cells.log\",\n",
    "                             \"#SBATCH --job-name=count_cells\",\n",
    "                             f\"#SBATCH --partition={cluster_queue_counting}\",\n",
    "                             f\"#SBATCH --qos={cluster_queue_counting}\\n\",\n",
    "                             f\"source /home/${{USER}}/.bashrc\\n\",\n",
    "                             \"date; echo\\n\\n\"])\n",
    "\n",
    "    script_body = \"\\n\".join([f'{cell_counting_script} -i {imagelist_csv_path} -o {cell_counts_csv_path} -r {run_name} -Nm {nuclei_min_size} -Cm {cells_min_size}\\n',\n",
    "                             \"echo; date\",\n",
    "                             \"sstat -j $SLURM_JOB_ID.batch --format=JobID,Node,MaxVMSize\\n\"])\n",
    "\n",
    "    #print(script_path)\n",
    "    with open(script_path, mode='w', encoding='utf-8') as f:\n",
    "        f.write(script_head)\n",
    "        f.write(script_body)\n",
    "    \n",
    "    with open(master_script_path, mode='a', encoding='utf-8') as f:\n",
    "        f.write(f\"chmod ug+rx {script_path}\\n\")\n",
    "        f.write(f\"sbatch {script_path}\\n\\n\")\n",
    "\n",
    "print(f\"chmod ug+rx {master_script_path}\")\n",
    "print(f\"{master_script_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab61e638-e9f5-49dc-b397-9a08a2a1dee9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. CellProfiler scripts\n",
    "1. **extract CellProfiler measurements for filtered cells, nuclei, and cytoplasm objects**\n",
    "    - perform in batches\n",
    "    - needs a (column) subset of the Images_list.csv file, without extracted cell paths (and unprocessed cellpose output):\n",
    "        - named `Images_list_CellProfiler.csv`, saved in the main measurement folder\n",
    "2. **merge batches**\n",
    "- note: for some reason calling the scripts from this notebook fails to load the CellProfiler module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e818333-0bbc-4198-9768-17234c0d2976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function, used in excluding columns in imagelist file not to pass to cellprofiler\n",
    "def contains_pattern(string, patterns):\n",
    "    for pattern in patterns:\n",
    "        if pattern in string:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "master_script_path = f'{scripts_folder}/{analysis_name}_04_cellprofiler.sh'\n",
    "with open(master_script_path, mode='w', encoding='utf-8') as f:\n",
    "        f.write(\"#!/bin/bash\\n\\n\")\n",
    "\n",
    "for run_folder_FFC in processed_runs:\n",
    "    run_name = get_run_name(run_folder_FFC)\n",
    "    # paths\n",
    "    scripts_folder_cellprofiler = f\"{scripts_folder}/{run_name}/04_cellprofiler/\"\n",
    "   \n",
    "    # temp folder for intermediary files - batches that need to be merged\n",
    "    tmp_folder_cellprofiler = f\"{tmp_files_folder}/{run_name}/cellprofiler_temp/\"\n",
    "    output_folder_cellprofiler = f\"{run_folder_FFC}/CellProfiler_measurements/\"\n",
    "\n",
    "    metadata_folder = f\"{run_folder_FFC}/Images_metadata/\"\n",
    "    imagelist_csv_path = f\"{metadata_folder}/{run_name}_images_list.csv\"\n",
    "    imagelist_csv_cellprofiler_path = f\"{metadata_folder}/{run_name}_images_list_CellProfiler.csv\"\n",
    "    index_xml_path = f\"{run_folder_FFC}/Images_FFC/{index_xml_filename}\"\n",
    "       \n",
    "    # generate imagelist subset\n",
    "    imagelist = pd.read_csv(imagelist_csv_path)\n",
    "    # define columns not to pass on to CellProfiler so that it does not load them\n",
    "    cols_keep = [col for col in imagelist.columns if not contains_pattern(col, [\"extracted_cells\", \"cellpose\", \"cytoself\", \"structural\", \"tagged\"])]\n",
    "    # save selected columns in a cellprofiler-specific imagelist\n",
    "    imagelist[cols_keep].to_csv(imagelist_csv_cellprofiler_path, index=None)\n",
    "    \n",
    "    n_batches = np.ceil(len(imagelist)/cellprofiler_batch_size).astype(\"int\")\n",
    "\n",
    "    script_path = f\"{scripts_folder_cellprofiler}/{run_name}_04_a_run_cellprofiler.sh\"\n",
    "    # create the script - the array line ensures one script is run for each batch\n",
    "    script_head = \"\\n\".join([f\"#!/bin/bash\",\n",
    "                             f\"#SBATCH --output {logs_folder}/job_%A_%3a_{run_name}_cellprofiler.log\",\n",
    "                             f\"#SBATCH --error {logs_folder}/job_%A_%3a_{run_name}_cellprofiler.log\",\n",
    "                             f\"#SBATCH --mem={maximum_memory}\",\n",
    "                             f\"#SBATCH --job-name=cellprofiler\",\n",
    "                             f\"#SBATCH --partition={cluster_queue_cellprofiler}\",\n",
    "                             f\"#SBATCH --qos={cluster_queue_cellprofiler}\",\n",
    "                             f\"#SBATCH --array=0-{max(range(n_batches))}:1%{max_arr_jobs}\\n\", \n",
    "                             \"source /home/${USER}/.bashrc\\n\",\n",
    "                             \"module load CellProfiler/4.2.1-foss-2020b\\n\\n\",                            \n",
    "                             \"date; echo\\n\",\n",
    "                             f\"echo {run_name}\\n\",\n",
    "                             'batch_i=$SLURM_ARRAY_TASK_ID',\n",
    "                             f'batch_size={cellprofiler_batch_size}\\n',\n",
    "                             f'maxa={len(imagelist)}',\n",
    "                             'start=$(( batch_i*batch_size +1 ))',\n",
    "                             'stop=$(( (batch_i+1)*batch_size ))',\n",
    "                             'if [ $stop -ge $maxa ]; then stop=$maxa; fi',\n",
    "                             f'printf -v tmp_folder_batch \"{tmp_folder_cellprofiler}/batch_%04d\" $batch_i',\n",
    "                             'echo $batch_i $start $stop',\n",
    "                             'echo $tmp_folder_batch\\n',\n",
    "                             ])\n",
    "\n",
    "    script_body = \"\\n\".join([f\"cellprofiler -c -r -p {cellprofiler_pipeline} --data-file {imagelist_csv_cellprofiler_path} -f $start -l $stop -o $tmp_folder_batch\\n\",\n",
    "                  \"echo; date\",\n",
    "                  \"sstat  -j   $SLURM_JOB_ID.batch   --format=JobID,Node,MaxVMSize\\n\"])\n",
    "    \n",
    "    with open(script_path, mode='w', encoding='utf-8') as f:\n",
    "        f.write(script_head)\n",
    "        f.write(script_body)\n",
    "        \n",
    "        \n",
    "    # merging of cellprofiler batches script\n",
    "    merging_script_path = f\"{scripts_folder_cellprofiler}/{run_name}_04_b_merge_cellprofiler_batches.sh\"\n",
    "\n",
    "    merging_script_head = \"\\n\".join([f\"#!/bin/bash\",\n",
    "                                     f\"#SBATCH --output {logs_folder}/job_%j_{run_name}_merge_CP_batches.log\",\n",
    "                                     f\"#SBATCH --error {logs_folder}/job_%j_{run_name}_merge_CP_batches.log\",\n",
    "                                     f\"#SBATCH --job-name=merge_CP\",\n",
    "                                     f\"#SBATCH --partition={cluster_queue}\",\n",
    "                                     f\"#SBATCH --qos={cluster_queue}\\n\",\n",
    "                                     f\"source /home/${{USER}}/.bashrc\\n\",\n",
    "                                     \"date; echo\\n\\n\"])\n",
    "\n",
    "    merging_script_body = \"\\n\".join([f'imagelist=\"{imagelist_csv_path}\"',\n",
    "                                     f'index_xml_path=\"{index_xml_path}\"',\n",
    "                                     f'batches_folder_root=\"{tmp_folder_cellprofiler}\"',\n",
    "                                     f'output_folder=\"{output_folder_cellprofiler}\"\\n',\n",
    "                                     f'{cellprofiler_batch_merging_script} -i $imagelist -x $index_xml_path -b $batches_folder_root -o $output_folder -v {opera_harmony_version}\\n',\n",
    "                                     \"echo; date\",\n",
    "                                     \"sstat -j $SLURM_JOB_ID.batch --format=JobID,Node,MaxVMSize\\n\"])\n",
    "\n",
    "    with open(merging_script_path, mode='w', encoding='utf-8') as f:\n",
    "        f.write(merging_script_head)\n",
    "        f.write(merging_script_body)\n",
    "    \n",
    "    # master script - include dependency of merging batches on running cellprofiler first\n",
    "    with open(master_script_path, mode='a', encoding='utf-8') as f:\n",
    "        f.write(f\"jid=$(sbatch --parsable {script_path})\\n\")\n",
    "        f.write(f\"chmod ug+rx {merging_script_path}\\n\")          \n",
    "        f.write(f\"sbatch --dependency=afterok:${{jid}} {merging_script_path}\\n\\n\")\n",
    "\n",
    "print(f\"chmod ug+rx {master_script_path}\")\n",
    "print(f\"{master_script_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ab659-d066-4b6d-b899-66acded56689",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Get random forest predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de04d02-8856-42a4-956a-005504bf546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_script_path = f'{scripts_folder}/{analysis_name}_05_get_CellProfiler_predictions.sh'\n",
    "with open(master_script_path, mode='w', encoding='utf-8') as f:\n",
    "        f.write(\"#!/bin/bash\\n\\n\")\n",
    "            \n",
    "for run_folder_FFC in processed_runs:\n",
    "    run_name = get_run_name(run_folder_FFC)\n",
    "    # paths\n",
    "    scripts_folder_get_cp_predictions = f\"{scripts_folder}/{run_name}/05_cellprofiler_predictions/\"\n",
    "\n",
    "    cellprofiler_measurements_path = f\"{run_folder_FFC}/CellProfiler_measurements/{run_name}_merged_cell_measurements.csv\"\n",
    "    output_path_cellprofiler_predictions = f\"{run_folder_FFC}/Predictions_CellProfiler_RF/{run_name}_predictions_cellprofiler_rf.csv\"\n",
    "    \n",
    "    script_path = f\"{scripts_folder_get_cp_predictions}/{run_name}_05_get_CellProfiler_predictions.sh\"\n",
    "\n",
    "    script_head = \"\\n\".join([f\"#!/bin/bash\",\n",
    "                             f\"#SBATCH --output {logs_folder}/job_%j_{run_name}_get_predictions.log\",\n",
    "                             f\"#SBATCH --error {logs_folder}/job_%j_{run_name}_get_predictions.log\",\n",
    "                             \"#SBATCH --job-name=get_predictions\",\n",
    "                             f\"#SBATCH --partition={cluster_queue_get_predictions}\",\n",
    "                             f\"#SBATCH --qos={cluster_queue_get_predictions}\\n\",\n",
    "                             f\"source /home/${{USER}}/.bashrc\\n\",\n",
    "                             \"date; echo\\n\\n\"])\n",
    "\n",
    "    script_body = \"\\n\".join([f\"measurement=\\\"{cellprofiler_measurements_path}\\\"\",\n",
    "                             f\"rf_model_path=\\\"{rf_model_path}\\\"\",\n",
    "                             f\"predictions_save_path={output_path_cellprofiler_predictions}\\n\",\n",
    "                             f'{get_rf_predictions_script} -i $measurement -m $rf_model_path -o $predictions_save_path\\n',\n",
    "                             \"echo; date\",\n",
    "                             \"sstat -j $SLURM_JOB_ID.batch --format=JobID,Node,MaxVMSize\\n\"])\n",
    "    \n",
    "    with open(script_path, mode='w', encoding='utf-8') as f:\n",
    "        f.write(script_head)\n",
    "        f.write(script_body)\n",
    "    \n",
    "    with open(master_script_path, mode='a', encoding='utf-8') as f:\n",
    "        f.write(f\"chmod ug+rx {script_path}\\n\")\n",
    "        f.write(f\"sbatch {script_path}\\n\\n\")\n",
    "\n",
    "print(f\"chmod ug+rx {master_script_path}\")\n",
    "print(f\"{master_script_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1863646-eaef-40d0-8543-f4c6b28e0562",
   "metadata": {},
   "source": [
    "## 6. Visualize random forest predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b039df2-69dc-40e7-8a50-6333900ec8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JPEG conversion - add flag if \n",
    "color_code_par = {False:\"\", True:\"--color_code_probas \"}[bool(color_code_probabilities)]\n",
    "\n",
    "master_script_path = f'{scripts_folder}/{analysis_name}_06_visualize_cellprofiler_predictions.sh'\n",
    "with open(master_script_path, mode='w', encoding='utf-8') as f:\n",
    "        f.write(\"#!/bin/bash\\n\\n\")\n",
    "\n",
    "for run_folder_FFC in processed_runs:\n",
    "    run_name = get_run_name(run_folder_FFC)\n",
    "    \n",
    "    scripts_folder_visualize_cp_predictions = f\"{scripts_folder}/{run_name}/06_visualize_cellprofiler_predictions/\"\n",
    "\n",
    "    # define folders/parameters to pass on to script\n",
    "    metadata_folder = f\"{run_folder_FFC}/Images_metadata/\"\n",
    "    imagelist_csv_path = f\"{metadata_folder}/{run_name}_images_list.csv\"\n",
    "    cellprofiler_predictions_path = f\"{run_folder_FFC}/Predictions_CellProfiler_RF/{run_name}_predictions_cellprofiler_rf.csv\"\n",
    "    \n",
    "    output_folder_visualizations = f\"{run_folder_FFC}/Predictions_CellProfiler_RF/\"\n",
    "    output_folder_comparison = f\"{output_folder_visualizations}/comparisons\"\n",
    "    output_folder_tagged_labeled = f\"{output_folder_visualizations}/labeled_tagged\"\n",
    "    \n",
    "    background_intensities_param = \" \".join([str(x) for x in background_intensities])\n",
    "    \n",
    "    script_path = f\"{scripts_folder_visualize_cp_predictions}/{run_name}_06_visualize_cellprofiler_predictions.sh\"\n",
    "\n",
    "    script_head = \"\\n\".join([f\"#!/bin/bash\",\n",
    "                             f\"#SBATCH --output {logs_folder}/job_%j_{run_name}_visualize_predictions.log\",\n",
    "                             f\"#SBATCH --error {logs_folder}/job_%j_{run_name}_visualize_predictions.log\",\n",
    "                             f\"#SBATCH --mem={maximum_memory}\",                            \n",
    "                             f\"#SBATCH --job-name=visualize_pred\",\n",
    "                             f\"#SBATCH --partition={cluster_queue_visualize_predictions}\",\n",
    "                             f\"#SBATCH --qos={cluster_queue_visualize_predictions}\\n\",\n",
    "                             f\"source /home/${{USER}}/.bashrc\\n\",\n",
    "                             \"date; echo\\n\\n\"])\n",
    "\n",
    "    script_body = \"\\n\".join([f'imagelist=\"{imagelist_csv_path}\"',\n",
    "                             f'predictions=\"{cellprofiler_predictions_path}\"',\n",
    "                             f'rf_model_path=\"{rf_model_path}\"\\n',\n",
    "                             f'output_comparison=\"{output_folder_comparison}\"',\n",
    "                             f'output_tagged=\"{output_folder_tagged_labeled}\"\\n',\n",
    "                             f'mkdir -p $output_comparison $output_tagged\\n',\n",
    "                             f'{visualize_predictions_script} -i $imagelist -p $predictions -r $rf_model_path -C $output_comparison -t $output_tagged -b {background_intensities_param} -n {minq} -x {maxq} -g {gamma} -Nm {nuclei_min_size} -Cm {cells_min_size} -c {colormap_path} {color_code_par} \\n',\n",
    "                             \"echo; date\",\n",
    "                             \"sstat -j $SLURM_JOB_ID.batch --format=JobID,Node,MaxVMSize\\n\"])\n",
    "    \n",
    "    with open(script_path, mode='w', encoding='utf-8') as f:\n",
    "        f.write(script_head)\n",
    "        f.write(script_body)\n",
    "    \n",
    "    with open(master_script_path, mode='a', encoding='utf-8') as f:\n",
    "        f.write(f\"chmod ug+rx {script_path}\\n\")\n",
    "        f.write(f\"sbatch {script_path}\\n\\n\")\n",
    "\n",
    "print(f\"chmod ug+rx {master_script_path}\")\n",
    "print(f\"{master_script_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e68c213-4431-4fc8-8d4b-709655304450",
   "metadata": {},
   "source": [
    "## 90. Get post-perturbation predictions (random forest chans subset + spatial info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f38de29-d72e-4615-80d7-b7e34e265de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the measurements by plate name; convention: pretreatment is always measurement 1\n",
    "runs = pd.DataFrame(processed_runs, columns=[\"run_folder\"])\n",
    "runs[\"run_name\"] = [get_run_name(path) for path in processed_runs]\n",
    "runs[\"plate\"] = [x.split(\"__\")[0] for x in runs[\"run_name\"]]\n",
    "runs[\"measurement\"] = [int(x.split(\"-\")[-1].strip(\"_FFC\").split(\"_\")[1]) for x in runs[\"run_name\"]]\n",
    "runs[\"cellprofiler_path\"] = [f'{runs.loc[i, \"run_folder\"]}/CellProfiler_measurements/{runs.loc[i, \"run_name\"]}_merged_cell_measurements.csv' for i in range(len(runs))]\n",
    "runs[\"predictions_path\"] = [f'{runs.loc[i, \"run_folder\"]}/Predictions_CellProfiler_RF/{runs.loc[i, \"run_name\"]}_predictions_cellprofiler_rf.csv' for i in range(len(runs))]\n",
    "\n",
    "plates = sorted(runs.plate.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9937be-3a84-445e-a98c-a8633eed5d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_script_path = f'{scripts_folder}/{analysis_name}_90_get_post_perturb_predictions.sh'\n",
    "with open(master_script_path, mode='w', encoding='utf-8') as f:\n",
    "        f.write(\"#!/bin/bash\\n\\n\")\n",
    "\n",
    "for plate in tqdm(plates):\n",
    "    runs_plate = runs[runs[\"plate\"] == plate]\n",
    "    \n",
    "    # first measurement\n",
    "    pretreatment_idx = runs_plate[runs_plate.measurement == 1].index[0]\n",
    "    pretreatment_preds_path = runs_plate.loc[pretreatment_idx, \"predictions_path\"]\n",
    "    # all other treatments\n",
    "    treat_idxs = runs_plate[runs_plate.index != pretreatment_idx].index\n",
    "    \n",
    "    # generate the necessary scripts for all post-treatment measurements\n",
    "    for idx in treat_idxs:\n",
    "        run_folder_FFC = runs.loc[idx, \"run_folder\"]\n",
    "        run_name = get_run_name(run_folder_FFC)\n",
    "        \n",
    "        scripts_folder_get_predictions_post_perturb = f\"{scripts_folder}/{run_name}/90_get_predictions_post_perturb\"\n",
    "        os.system(f\"mkdir -p {scripts_folder_get_predictions_post_perturb}\")\n",
    "             \n",
    "        ## get spatial info predictions\n",
    "        cellprofiler_treated_path = runs.loc[idx, \"cellprofiler_path\"]\n",
    "        spatial_preds_output_path = f'{run_folder_FFC}/Predictions_CellProfiler_RF/{run_name}_spatial_info_scores.csv'\n",
    "        \n",
    "        script_path = f\"{scripts_folder_get_predictions_post_perturb}/{run_name}_90a_get_spatial_info.sh\"\n",
    "\n",
    "        script_head = \"\\n\".join([f\"#!/bin/bash\",\n",
    "                                 f\"#SBATCH --output {logs_folder}/job_%j_{run_name}_get_spatial_info.log\",\n",
    "                                 f\"#SBATCH --error {logs_folder}/job_%j_{run_name}_get_spatial_info.log\",\n",
    "                                 f\"#SBATCH --mem={maximum_memory}\",                                 \n",
    "                                 f\"#SBATCH --job-name=spatial_preds\",\n",
    "                                 f\"#SBATCH --partition={cluster_queue_post_perturb_detection}\",\n",
    "                                 f\"#SBATCH --qos={cluster_queue_post_perturb_detection}\\n\",\n",
    "                                 f\"source /home/${{USER}}/.bashrc\\n\",\n",
    "                                 \"date; echo\\n\\n\"])\n",
    "        \n",
    "        script_body = \"\\n\".join([f'cells_T1_path=\"{cellprofiler_treated_path}\"',\n",
    "                                 f'predictions_T0_path=\"{pretreatment_preds_path}\"',\n",
    "                                 f'output_path=\"{spatial_preds_output_path}\"',\n",
    "                                 f'radius={radius}\\n',\n",
    "                                 f'{extract_spatial_info_script} -c $cells_T1_path -p $predictions_T0_path -o $output_path -r $radius\\n',\n",
    "                                 \"echo; date\",\n",
    "                                 \"sstat -j $SLURM_JOB_ID.batch --format=JobID,Node,MaxVMSize\\n\"])\n",
    "        \n",
    "        with open(script_path, mode='w', encoding='utf-8') as f:\n",
    "            f.write(script_head)\n",
    "            f.write(script_body)\n",
    "        # master script - prepare dependencies\n",
    "        with open(master_script_path, mode='a', encoding='utf-8') as f:\n",
    "            f.write(f\"# {run_name}\\n\")\n",
    "            f.write(f\"jids=$(sbatch --parsable {script_path})\\n\")\n",
    "            \n",
    "        ## get channel subsets model predictions\n",
    "        channel_subsets_preds_output_path_basename = f'{run_folder_FFC}/Predictions_CellProfiler_RF/{run_name}_predictions_cellprofiler_rf_channelsubset'\n",
    "\n",
    "        for i, (rf_name, rf_path) in enumerate(rf_models_channels_subsets.items()):\n",
    "            script_path = f\"{scripts_folder_get_predictions_post_perturb}/{run_name}_90b_get_CellProfiler_predictions_channel_subsets_{i:02d}_{rf_name}.sh\"\n",
    "            predictions_output_path = f\"{channel_subsets_preds_output_path_basename}_{i:02d}_{rf_name}.csv\"\n",
    "\n",
    "            script_head = \"\\n\".join([f\"#!/bin/bash\",\n",
    "                                     f\"#SBATCH --output {logs_folder}/job_%j_{run_name}_get_predictions_channelsubsets_{i:02d}_{rf_name}.log\",\n",
    "                                     f\"#SBATCH --error {logs_folder}/job_%j_{run_name}_get_predictions_channelsubsets_{i:02d}_{rf_name}.log\",\n",
    "                                     f\"#SBATCH --mem={maximum_memory}\",                                 \n",
    "                                     f\"#SBATCH --job-name=get_predictions\",\n",
    "                                     f\"#SBATCH --partition={cluster_queue_get_predictions}\",\n",
    "                                     f\"#SBATCH --qos={cluster_queue_get_predictions}\\n\",\n",
    "                                     f\"source /home/${{USER}}/.bashrc\\n\",\n",
    "                                     \"date; echo\\n\\n\"])\n",
    "\n",
    "            script_body = \"\\n\".join([f\"measurement=\\\"{cellprofiler_treated_path}\\\"\",\n",
    "                                     f\"rf_model_path=\\\"{rf_path}\\\"\",\n",
    "                                     f\"predictions_save_path={predictions_output_path}\\n\",\n",
    "                                     f'{get_rf_predictions_script} -i $measurement -m $rf_model_path -o $predictions_save_path\\n',\n",
    "                                     \"echo; date\",\n",
    "                                     \"sstat -j $SLURM_JOB_ID.batch --format=JobID,Node,MaxVMSize\\n\"])\n",
    "\n",
    "            with open(script_path, mode='w', encoding='utf-8') as f:\n",
    "                f.write(script_head)\n",
    "                f.write(script_body)\n",
    "                \n",
    "            # master script - prepare dependencies\n",
    "            with open(master_script_path, mode='a', encoding='utf-8') as f:\n",
    "                f.write(f\"jids=$jids,$(sbatch --parsable {script_path})\\n\")\n",
    "                \n",
    "        \n",
    "        ## final script combining the spatial info with channel subsets\n",
    "        script_path = f\"{scripts_folder_get_predictions_post_perturb}/{run_name}_90c_combine_predictions_spatial_info.sh\"\n",
    "        final_predictions_output_path = f'{run_folder_FFC}/Predictions_CellProfiler_RF/{run_name}_final_predictions.csv'\n",
    "\n",
    "        script_head = \"\\n\".join([f\"#!/bin/bash\",\n",
    "                                 f\"#SBATCH --output {logs_folder}/job_%j_{run_name}_combine_predictions_spatial.log\",\n",
    "                                 f\"#SBATCH --error {logs_folder}/job_%j_{run_name}_combine_predictions_spatial.log\",\n",
    "                                 f\"#SBATCH --mem={maximum_memory}\",                                 \n",
    "                                 f\"#SBATCH --job-name=combine_predictions\",\n",
    "                                 f\"#SBATCH --partition={cluster_queue_post_perturb_detection}\",\n",
    "                                 f\"#SBATCH --qos={cluster_queue_post_perturb_detection}\\n\",\n",
    "                                 f\"source /home/${{USER}}/.bashrc\\n\",\n",
    "                                 \"date; echo\\n\\n\"])\n",
    "        \n",
    "        script_body = \"\\n\".join([f'predictions_spatial_path=\"{spatial_preds_output_path}\"',\n",
    "                                 f'predictions_RF_multiple_substring=\"{channel_subsets_preds_output_path_basename}\"',\n",
    "                                 f'output_path=\"{final_predictions_output_path}\"',\n",
    "                                 f'{combine_predictions_script} -s $predictions_spatial_path -p $predictions_RF_multiple_substring -o $output_path\\n',\n",
    "                                 \"echo; date\",\n",
    "                                 \"sstat -j $SLURM_JOB_ID.batch --format=JobID,Node,MaxVMSize\\n\"])\n",
    "        \n",
    "        with open(script_path, mode='w', encoding='utf-8') as f:\n",
    "            f.write(script_head)\n",
    "            f.write(script_body)        \n",
    "            \n",
    "        with open(master_script_path, mode='a', encoding='utf-8') as f:\n",
    "            f.write(f\"sbatch --dependency=afterok:$jids {script_path}\\n\\n\")\n",
    "    print() \n",
    "\n",
    "print(f\"chmod ug+rx {master_script_path}\")\n",
    "print(f\"{master_script_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f930b958-127c-443f-8b0d-d4e4e927e668",
   "metadata": {},
   "source": [
    "## 91. Statistical tests - CellProfiler features, post-perturbation, treated vs DMSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1348ca45-bb4f-47da-9bc9-e2a9a1cb8d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the measurements by plate name; convention: pretreatment is always measurement 1\n",
    "runs = pd.DataFrame(processed_runs, columns=[\"run_folder\"])\n",
    "runs[\"run_name\"] = [get_run_name(path) for path in processed_runs]\n",
    "runs[\"plate\"] = [x.split(\"__\")[0] for x in runs[\"run_name\"]]\n",
    "runs[\"measurement\"] = [int(x.split(\"-\")[-1].strip(\"_FFC\").split(\"_\")[1]) for x in runs[\"run_name\"]]\n",
    "runs[\"cellprofiler_path\"] = [f'{runs.loc[i, \"run_folder\"]}/CellProfiler_measurements/{runs.loc[i, \"run_name\"]}_merged_cell_measurements.csv' for i in range(len(runs))]\n",
    "runs[\"predictions_all_path\"] = [f'{runs.loc[i, \"run_folder\"]}/Predictions_CellProfiler_RF/{runs.loc[i, \"run_name\"]}_predictions_cellprofiler_rf.csv' for i in range(len(runs))]\n",
    "runs[\"predictions_final_path\"] = [f'{runs.loc[i, \"run_folder\"]}/Predictions_CellProfiler_RF/{runs.loc[i, \"run_name\"]}_final_predictions.csv' for i in range(len(runs))]\n",
    "\n",
    "plates = sorted(runs.plate.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a73d07-6449-4f58-b6fd-6d43c4c9d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_script_path = f'{scripts_folder}/{analysis_name}_91_test_statistics_cellprofiler_features.sh'\n",
    "with open(master_script_path, mode='w', encoding='utf-8') as f:\n",
    "        f.write(\"#!/bin/bash\\n\\n\")\n",
    "\n",
    "for plate in tqdm(plates):\n",
    "    runs_plate = runs[runs[\"plate\"] == plate]\n",
    "    \n",
    "    # first measurement\n",
    "    pretreatment_idx = runs_plate[runs_plate.measurement == 1].index[0]\n",
    "    # all other treatments\n",
    "    treat_idxs = runs_plate[runs_plate.index != pretreatment_idx].index\n",
    "    \n",
    "    # generate the necessary scripts for all post-treatment measurements\n",
    "    for idx in treat_idxs:\n",
    "        run_folder_FFC = runs.loc[idx, \"run_folder\"]\n",
    "        run_name = get_run_name(run_folder_FFC)\n",
    "        \n",
    "        scripts_folder_test_statistics = f\"{scripts_folder}/{run_name}/91_test_statistics_cellprofiler_features\"\n",
    "        os.system(f\"mkdir -p {scripts_folder_test_statistics}\")\n",
    "             \n",
    "        ## get spatial info predictions\n",
    "        cellprofiler_path = runs.loc[idx, \"cellprofiler_path\"]\n",
    "        predictions_final_path = runs.loc[idx, \"predictions_final_path\"]\n",
    "        predictions_all_path = runs.loc[idx, \"predictions_all_path\"]\n",
    "        test_scores_outfile = f\"{hit_calling_folder}/{run_name}_cellprofiler_features_pvals.csv\"\n",
    "        \n",
    "        script_path = f\"{scripts_folder_test_statistics}/{run_name}_91_test_statistics_cellprofiler_features.sh\"\n",
    "\n",
    "        script_head = \"\\n\".join([f\"#!/bin/bash\",\n",
    "                                 f\"#SBATCH --output {logs_folder}/job_%j_{run_name}_test_statistics_cellprofiler_features.log\",\n",
    "                                 f\"#SBATCH --error {logs_folder}/job_%j_{run_name}_test_statistics_cellprofiler_features.log\",\n",
    "                                 f\"#SBATCH --mem={maximum_memory}\",                                 \n",
    "                                 f\"#SBATCH --job-name=test_stat\",\n",
    "                                 f\"#SBATCH --partition={cluster_queue_hit_calling}\",\n",
    "                                 f\"#SBATCH --qos={cluster_queue_hit_calling}\\n\",\n",
    "                                 f\"source /home/${{USER}}/.bashrc\\n\",\n",
    "                                 \"date; echo\\n\\n\"])\n",
    "        \n",
    "        script_body = \"\\n\".join([f'measurement_name=\"{run_name}\"',\n",
    "                                 f'features_list_path=\"{features_to_test_path}\"',\n",
    "                                 f'platemap_path=\"{platemap_path}\"',\n",
    "                                 f'clones_metadata_path=\"{clones_metadata_path}\"',\n",
    "                                 f'cellprofiler_path=\"{cellprofiler_path}\"',\n",
    "                                 f'imagelist_path={run_folder_FFC}/Images_metadata/{run_name}_images_list.csv',\n",
    "                                 f'predictions_final_path=\"{predictions_final_path}\"',\n",
    "                                 f'predictions_all_path=\"{predictions_all_path}\"',\n",
    "                                 f'predictions_final_path=\"{predictions_final_path}\"',\n",
    "                                 f'test_scores_outfile=\"{test_scores_outfile}\"\\n',\n",
    "                                 \n",
    "                                 f'{test_statistic_cellprofiler_script} -m $measurement_name -f $features_list_path -pm $platemap_path -cm $clones_metadata_path -cp $cellprofiler_path -i $imagelist_path -pf $predictions_final_path -pa $predictions_all_path -o $test_scores_outfile\\n',\n",
    "                                 \"echo; date\",\n",
    "                                 \"sstat -j $SLURM_JOB_ID.batch --format=JobID,Node,MaxVMSize\\n\"])\n",
    "        \n",
    "        with open(script_path, mode='w', encoding='utf-8') as f:\n",
    "            f.write(script_head)\n",
    "            f.write(script_body)\n",
    "        # master script - prepare dependencies\n",
    "        with open(master_script_path, mode='a', encoding='utf-8') as f:\n",
    "            f.write(f\"# {run_name}\\n\")\n",
    "            f.write(f\"jids=$(sbatch --parsable {script_path})\\n\")\n",
    "            \n",
    "print(f\"chmod ug+rx {master_script_path}\")\n",
    "print(f\"{master_script_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
